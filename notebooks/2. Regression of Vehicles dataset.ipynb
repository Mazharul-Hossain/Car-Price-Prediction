{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Vehicles dataset (Beginner's Analysis)\n",
    "\n",
    "1.2 Million Used Car Listings\n",
    "1.2 Million listings scraped from TrueCar.com - Price, Mileage, Make, Model\n",
    "\n",
    "link: https://www.kaggle.com/jpayne/852k-used-car-listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First we import necessary Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Reading and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vehicles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv(\"datasets/true_car_listings.csv\")\n",
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicles.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(vehicles.columns)\n",
    "columns.remove('Price')\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Dataset for car from 1970 and price is not greater than 50k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_top_price = vehicles.loc[(vehicles.Year>=1970) & (vehicles.Price>=1000) & (vehicles.Price<=50000) \n",
    "#                                  & (vehicles.Mileage<=300000)].loc[:, ['Price', 'Year', \n",
    "#                                                                                 'Mileage', 'City', 'State', 'Make', 'Model']]\n",
    "\n",
    "vehicle_top_price = vehicles.loc[(vehicles.Year>=1970) & (vehicles.Price>=1000) & (vehicles.Price<=50000) \n",
    "                                 & (vehicles.Mileage<=300000)]\n",
    "vehicle_top_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/45355563/2049763\n",
    "vehicle_top_price = vehicle_top_price.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['City', 'Make', 'Model']:\n",
    "    vehicle_top_price[col] = vehicle_top_price[col].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = vehicle_top_price['State'] == \"CO\"\n",
    "Counter(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = vehicle_top_price['State'].unique().tolist()\n",
    "state_list.sort()\n",
    "len(state_list), \", \".join(state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Oh'), 'State'] = 'OH'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Va'), 'State'] = 'VA'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Md'), 'State'] = 'MD'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Ca'), 'State'] = 'CA'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Ga'), 'State'] = 'GA'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'ga'), 'State'] = 'GA'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Fl'), 'State'] = 'FL'\n",
    "vehicle_top_price.loc[(vehicle_top_price['State'] == 'Az'), 'State'] = 'AZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Drop Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop null rows\n",
    "vehicle_top_price = vehicle_top_price.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_top_price.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pp.ProfileReport(vehicle_top_price, title='Pandas Profiling Report', explorative=True)\n",
    "profile.to_widgets()\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Normalize the Data\n",
    "Used Cars Price Prediction by 15 models\n",
    "https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_price_mean = vehicle_top_price['Price'].mean()\n",
    "vehicle_top_price['Price'] = (vehicle_top_price['Price'] / car_price_mean).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_year_min = vehicle_top_price['Year'].min()\n",
    "vehicle_top_price['Year'] = (vehicle_top_price['Year'] - car_year_min).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_mileage_mean = vehicle_top_price['Mileage'].mean()\n",
    "vehicle_top_price['Mileage'] = (vehicle_top_price['Mileage'] / car_mileage_mean).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform one hot encoding on multiple categorical columns: https://datascience.stackexchange.com/a/71805\n",
    "# # https://stackoverflow.com/a/44601764\n",
    "# vehicle_top_price = pd.get_dummies(vehicle_top_price, columns=['City', 'State', 'Make', 'Model'], drop_first=True)\n",
    "# vehicle_top_price.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "label_encoder = {}\n",
    "for col in ['City', 'State', 'Make', 'Model']:\n",
    "    label_encoder[col] = LabelEncoder()\n",
    "    label_encoder[col].fit(list(vehicle_top_price[col].astype(str).values))\n",
    "    vehicle_top_price[col] = label_encoder[col].transform(list(vehicle_top_price[col].astype(str).values))\n",
    "    label_encoder[col].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicle_top_price.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_top_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_top_price.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_top_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.graphics.api as smg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "sns.set_theme()\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "# sns.pairplot(vehicle_top_price, hue=\"Price\", diag_kind=\"hist\")\n",
    "g = sns.pairplot(vehicle_top_price)\n",
    "g.fig.set_size_inches(35,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_n = pp.ProfileReport(vehicle_top_price, title='Pandas Profiling Report')\n",
    "profile_n.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor \n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, VotingRegressor \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_d(y_meas, pred_y):\n",
    "    # Relative error between predicted y_pred and measured y_meas values\n",
    "    return mean_absolute_error(y_meas, pred_y)*len(y_meas)/sum(abs(y_meas))\n",
    "\n",
    "def acc_rmse(y_meas, pred_y):\n",
    "    # RMSE between predicted y_pred and measured y_meas values\n",
    "    return (mean_squared_error(y_meas, pred_y))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy_model(kf5, Model, feature, target):\n",
    "    r2_scores, rmse = [], []\n",
    "    for train_index, test_index in kf5.split(feature):\n",
    "        train_x = np.array(feature.iloc[train_index][:])\n",
    "        test_x  = np.array(feature.iloc[test_index][:])\n",
    "\n",
    "        train_y =  target.iloc[train_index][:]\n",
    "        test_y  =  target.iloc[test_index][:]\n",
    "\n",
    "        model = Model().fit(train_x, train_y)\n",
    "        \n",
    "        pred_train = model.predict(train_x)\n",
    "        pred_y = model.predict(test_x)\n",
    "        \n",
    "        print(\"\\n# training performance\")\n",
    "        acc_train_r2_num = round(r2_score(train_y, pred_train) * 100, 2)\n",
    "        print('acc(r2_score) for training =', acc_train_r2_num)  \n",
    "        \n",
    "        acc_train_d_num = round(acc_d(train_y, pred_train) * 100, 2)\n",
    "        print('acc(relative error) for training =', acc_train_d_num)  \n",
    "        \n",
    "        acc_train_rmse_num = round(acc_rmse(train_y, pred_train) * 100, 2)\n",
    "        print('acc(rmse) for training =', acc_train_rmse_num) \n",
    "        \n",
    "        print(\"# Test performance\")\n",
    "        acc_train_r2_num = round(r2_score(test_y, pred_y) * 100, 2)\n",
    "        print('acc(r2_score) for testing =', acc_train_r2_num)  \n",
    "        r2_scores.append(acc_train_r2_num)\n",
    "        \n",
    "        acc_train_d_num = round(acc_d(test_y, pred_y) * 100, 2)\n",
    "        print('acc(relative error) for testing =', acc_train_d_num)  \n",
    "        \n",
    "        acc_train_rmse_num = round(acc_rmse(test_y, pred_y) * 100, 2)\n",
    "        print('acc(rmse) for testing =', acc_train_rmse_num) \n",
    "        rmse.append(acc_train_rmse_num)        \n",
    "\n",
    "    print(\"\\nAvg R2 Score:\", round(np.mean(r2_scores), 3))\n",
    "    \n",
    "    rmse_mean = np.mean(rmse) \n",
    "    print(\"Avg RMSE (normalized): {} & in $ value: {}\".format(round(rmse_mean, 3), \n",
    "                                                              round(rmse_mean * car_price_mean / 100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added some parameters\n",
    "# https://stackoverflow.com/a/45116022\n",
    "k_fold_5 = KFold(n_splits = 5, shuffle = True, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_name = 'Price'\n",
    "train_target = vehicle_top_price[target_name]\n",
    "\n",
    "vehicle_top_price = vehicle_top_price.drop([target_name], axis=1)\n",
    "vehicle_top_price.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0, test0, train_target0, test_target0 = train_test_split(vehicle_top_price, \n",
    "                                                              train_target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# models = []\n",
    "# SVR, \n",
    "for Model in [LinearRegression, LinearSVR, SGDRegressor, DecisionTreeRegressor, RandomForestRegressor, \n",
    "              BaggingRegressor, ExtraTreesRegressor, AdaBoostRegressor]:    \n",
    "    print(\"\\n# Training for {} starting ****\".format(Model))\n",
    "    \n",
    "#     if Model == RidgeCV:\n",
    "#         model = Model(cv=5)\n",
    "#     else:\n",
    "#         model = Model() \n",
    "    accuracy_model(k_fold_5, Model, train0, train_target0)\n",
    "    \n",
    "#     if Model == RandomForestRegressor:\n",
    "#         print(model.best_params_)\n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = MLPRegressor()\n",
    "# param_grid = {'hidden_layer_sizes': [i for i in range(2,20)],\n",
    "#               'activation': ['relu'],\n",
    "#               'solver': ['adam'],\n",
    "#               'learning_rate': ['constant'],\n",
    "#               'learning_rate_init': [0.01],\n",
    "#               'power_t': [0.5],\n",
    "#               'alpha': [0.0001],\n",
    "#               'max_iter': [1000],\n",
    "#               'early_stopping': [True],\n",
    "#               'warm_start': [False]}\n",
    "# mlp_GS = GridSearchCV(mlp, param_grid=param_grid, \n",
    "#                    cv=10, verbose=True, pre_dispatch='2*n_jobs')\n",
    "# accuracy_model(k_fold_5, mlp_GS, vehicle_top_price, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting_Reg = VotingRegressor(estimators=[('lin', linreg), ('ridge', ridge), ('sgd', sgd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_regressor = RandomForestRegressor().fit(train0, train_target0)\n",
    "pred_y = random_forest_regressor.predict(test0)\n",
    "\n",
    "print(\"# Test performance\")\n",
    "acc_train_r2_num = round(r2_score(test_target0, pred_y) * 100, 2)\n",
    "print('acc(r2_score) for testing =', acc_train_r2_num)  \n",
    "\n",
    "acc_train_d_num = round(acc_d(test_target0, pred_y) * 100, 2)\n",
    "print('acc(relative error) for testing =', acc_train_d_num)  \n",
    "\n",
    "acc_train_rmse_num = round(acc_rmse(test_target0, pred_y) * 100, 2)\n",
    "print('acc(rmse) for testing =', acc_train_rmse_num, \"$\", round(acc_train_rmse_num * car_price_mean / 100, 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(random_forest_regressor, open('r_model_random_forest_regressor.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('r_model_random_forest_regressor.pkl.pkl','rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
